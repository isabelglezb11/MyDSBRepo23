---
title: "Homerwork 1"
author: "Isabel Gonzalez"
date: 2023-05-14
format: 
  docx: default
  html:
    toc: true
    toc_float: true
    code-fold: true
editor: visual
---

```{r}
#| label: load-libraries
#| echo: false # This option disables the printing of code (only output is displayed).
#| message: false
#| warning: false

library(tidyverse)
library(nycflights13)
library(skimr)

```

# Data Manipulation

## Problem 1: Use logical operators to find flights that:

```         
-   Had an arrival delay of two or more hours (\> 120 minutes)
-   Flew to Houston (IAH or HOU)
-   Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
-   Departed in summer (July, August, and September)
-   Arrived more than two hours late, but didn't leave late
-   Were delayed by at least an hour, but made up over 30 minutes in flight
```

```{r}
#| label: problem-1

# Had an arrival delay of two or more hours (> 120 minutes)

flights %>%
  filter(arr_delay >= 120)

# Flew to Houston (IAH or HOU)

flights %>%
  filter(dest %in% c("HOU", "IAH"))

# Were operated by United (`UA`), American (`AA`), or Delta (`DL`)

flights %>%
  filter(carrier %in% c("UA", "AA", "DL"))

# Departed in summer (July, August, and September)

flights %>%
  filter(month %in% c(7, 8, 9))  
  
# Arrived more than two hours late, but didn't leave late

flights %>%
  filter(arr_delay > 120, dep_delay == 0)

# Were delayed by at least an hour, but made up over 30 minutes in flight

flights %>%
  filter(dep_delay-arr_delay> 30 , dep_delay >= 60)

```

## Problem 2: What months had the highest and lowest proportion of cancelled flights? Interpret any seasonal patterns. To determine if a flight was cancelled use the following code

<!-- -->

```         
flights %>% 
  filter(is.na(dep_time)) 
```

```{r}
#| label: problem-2

# What months had the highest and lowest % of cancelled flights?

#create a new table (flights_cancelled) with a line for each month and three columns (# of cancelled flights, # of total flights and % of cancelled flights)

flights_c <- flights %>%
  group_by(month) %>%
  summarize(cancelled = sum(is.na(dep_time)),
            total = n()) %>% 
  mutate(percent_c = cancelled / total) 
  
#months with highest and lowest % of cancelled flights
  
highest_cancelled <- filter(flights_c, percent_c == max(percent_c))$month
lowest_cancelled <- filter(flights_c, percent_c== min(percent_c))$month

#print
flights_c
highest_cancelled
lowest_cancelled


```

## Problem 3: What plane (specified by the `tailnum` variable) traveled the most times from New York City airports in 2013? Please `left_join()` the resulting table with the table `planes` (also included in the `nycflights13` package).

For the plane with the greatest number of flights and that had more than 50 seats, please create a table where it flew to during 2013.

```{r}
# filter planes that departed from New York City airports, group them by tailnumber and count the number of flights for each plane that flew from that airport

num_flights_nyc <- flights %>%
  filter(origin %in% c("JFK", "EWR", "LGA")) %>%
  group_by(tailnum) %>%
  summarise(num_flights = n()) 
  
# join tables
  
joint_flights_planes <- num_flights_nyc %>%
  left_join(planes, by = "tailnum") %>%
arrange(desc(num_flights))

# plane that travel the most 

planethattraveledthemost <- filter(joint_flights_planes, num_flights== max(num_flights))$tailnum

# print 
planethattraveledthemost
joint_flights_planes
  
# plane with more than 50 seats

fiftyseats <- joint_flights_planes %>%
  filter(seats > 50)

plane_fifty <- filter(fiftyseats, num_flights== max(num_flights))$tailnum

# print 

fiftyseats
plane_fifty

#create table of destinations for plane that traveled the most with more than 50 seats ("plane_fifty")

plane_destinations <- flights %>%
  filter(tailnum == plane_fifty) %>%
  distinct(dest)


plane_destinations
```

## Problem 4: The `nycflights13` package includes a table (`weather`) that describes the weather during 2013. Use that table to answer the following questions:

According to the histogram of the historical data of temperatures in July 2013, the data is normally distributed with a slight right skew After plotting the data of "dewp" vs. "humid" we can see the blue line that represents a positive relation between the two variables After plotting the data of "precip" vs. "visib" we can see that there is no relation between the two variables

```         
-   What is the distribution of temperature (`temp`) in July 2013? Identify any important outliers in terms of the `wind_speed` variable.
-   What is the relationship between `dewp` and `humid`?
-   What is the relationship between `precip` and `visib`?
```

```{r}
# filter and plot only the temperatures from July 2013, I used the histogram to identify the distribution of the data
weather_july <- weather %>%
  filter(month == 7) 

temp_plot <-
ggplot(weather_july,aes(x=temp))+geom_histogram(binwidth = 0.5)+ggtitle("Distribution of Temperatures in July 2013")

temp_plot

# filter and plot only the wind_speed from July 2013
  
wind_speed_plot <-
ggplot(weather_july,aes(x=wind_speed))+geom_histogram(binwidth = 0.5, na.rm = TRUE)+ggtitle("Distribution of Wind speed data in July 2013")
wind_speed_plot

# Extract the wind_speed column
wind_speed <- weather_july$wind_speed

# Calculate the mean and standard deviation
mean_wind_speed <- mean(wind_speed, na.rm = TRUE)
sd_wind_speed <- sd(wind_speed, na.rm = TRUE)

# Calculate the lower and upper thresholds
lower_threshold <- mean_wind_speed - 3 * sd_wind_speed
upper_threshold <- mean_wind_speed + 3 * sd_wind_speed

# Identify outliers
outliers <- wind_speed[wind_speed < lower_threshold | wind_speed > upper_threshold]
#delete NAs from the answer
outliers <- outliers[!is.na(outliers)]

# Create a data frame with outliers as separate rows
outliers_table <- data.frame(Outliers = outliers)

# Print the table
print(outliers_table)

#Plot to observe the relationship between `dewp` and `humid`
dewp_humid_plot <-
ggplot(weather,aes(x=dewp, y=humid))+geom_point(na.rm = TRUE)+scale_y_log10()+ggtitle("Relationship between dewp and humid") + geom_smooth(method = "lm", se = FALSE,na.rm = TRUE)
dewp_humid_plot

# Plot to observe the relationship between `precip` and `visib`
precip_visib_plot <- ggplot(weather, aes(x = precip, y = visib)) +
  geom_point(na.rm = TRUE) +
  ggtitle("Relationship between precip and visib") 

precip_visib_plot
```

## Problem 5: Use the `flights` and `planes` tables to answer the following questions:

```         
-   How many planes have a missing date of manufacture?
-   What are the five most common manufacturers?
-   Has the distribution of manufacturer changed over time as reflected by the airplanes flying from NYC in 2013? (Hint: you may need to use case_when() to recode the manufacturer name and collapse rare vendors into a category called Other.)
```

```{r}


#How many planes have a missing date of manufacture?
# Count the number of planes that have NA in the year column
non_manufacture_date <- planes %>% 
  filter(is.na(year)) %>%
  count()

non_manufacture_date  

# What are the five most common manufacturers?
#Create a new table with the columns manufacturer and number_of_planes, arranged in descending order
top_manufacturers <- planes %>% 
  group_by(manufacturer)%>%
  summarise(number_of_planes=n())%>%
arrange(,desc(number_of_planes)) %>%
#slect the first five rows and all of the columns in the table
   top_n(5, number_of_planes)

top_manufacturers

# Has the distribution of manufacturer changed over time as reflected by the airplanes flying from NYC in 2013? (Hint: you may need to use case_when() to recode the manufacturer name and collapse rare vendors into a category called Other.)

flights_man <- flights %>%
  inner_join(planes, by = 'tailnum') %>% 
  mutate(manufacturer = case_when(
    grepl("BOEING", manufacturer) ~ "Boeing",
    grepl("AIRBUS INDUSTRIE", manufacturer) ~ "Airbus Industrie",
    grepl("EMBRAER", manufacturer) ~ "Embraer",
    grepl("BOMBARDIER INC", manufacturer) ~ "Bombardier Inc",
    grepl("AIRBUS", manufacturer) ~ "Airbus",
    TRUE ~ "Other"
  ))

flights_man

ggplot(flights_man, aes(x= year.y, fill = manufacturer)) +
  geom_bar() +
  labs(title = "Distribution of airplane manufacturers over time",
       x = "Year",
       y = "Number of flights",
       color = "Manufacturer") +
  scale_x_discrete(breaks = seq(1930, 2020, 5)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Problem 6: Use the `flights` and `planes` tables to answer the following questions:

```         
-   What is the oldest plane (specified by the tailnum variable) that flew from New York City airports in 2013?
-   How many airplanes that flew from New York City are included in the planes table?
```

```{r}
#What is the oldest plane (specified by the tailnum variable) that flew from New York City airports in 2013?
# Filter flights from New York airports
flights_nyc <- flights %>%
  filter(origin %in% c("JFK", "LGA", "EWR"))

# Left join to planes table to know the details on the planes
flights_nyc_planes <- flights_nyc %>%
  left_join(planes, by = "tailnum") %>%
  arrange(year.y) 
flights_nyc_planes

#find the oldest plane
oldest_plane <- filter(flights_nyc_planes, year.y == min(year.y, na.rm = TRUE)) %>%
  distinct(tailnum)

oldest_plane

#How many airplanes that flew from New York City are included in the planes table?
#remove lines with NA values and remove repeated tailnum
planes_clean <-  na.omit(flights_nyc_planes) %>%
  distinct(tailnum)

planes_clean

#count the number of lines on the table
count_planes <- length(planes_clean$tailnum)

count_planes

```

## Problem 7: Use the `nycflights13` to answer the following questions:

```         
-   What is the median arrival delay on a month-by-month basis in each airport?
-   For each airline, plot the median arrival delay for each month and origin airport.
```

```{r}


# What is the median arrival delay on a month-by-month basis in each airport?

median_delay <- flights %>%
  group_by(origin, month) %>%
  summarize(median_arr_delay=median(arr_delay, na.rm = TRUE))

median_delay

ggplot(median_delay, aes(x = month, y = median_arr_delay, color = origin)) +
  geom_line() +
  ggtitle("Median arrival delay by month") +
  expand_limits(y = -15) + 
  scale_x_continuous(breaks = seq(1, 12, 1))

#For each airline, plot the median arrival delay for each month and origin airport.

median_delay_airline <- flights %>%
  group_by(carrier, origin,month) %>%
  summarize(median_arr_delay_air=median(arr_delay, na.rm = TRUE))

median_delay_airline

ggplot(median_delay_airline, aes(x = month, y = median_arr_delay_air, color = origin)) +
  geom_line() +
  ggtitle("Median arrival delay by month") +
  facet_wrap(~ carrier) +
  ylim(min(median_delay_airline$median_arr_delay_air),max(median_delay_airline$median_arr_delay_air))+
  scale_x_continuous(breaks = seq(1, 12, 1))

```

## Problem 8: Let's take a closer look at what carriers service the route to San Francisco International (SFO). Join the `flights` and `airlines` tables and count which airlines flew the most to SFO. Produce a new dataframe, `fly_into_sfo` that contains three variables: the `name` of the airline, e.g., `United Air Lines Inc.` not `UA`, the count (number) of times it flew to SFO, and the `percent` of the trips that that particular airline flew to SFO.

```{r}

# join tables
joint_flights_airlines <- airlines %>%
  left_join(flights, by = "carrier") 

joint_flights_airlines

#Produce a new dataframe, `fly_into_sfo` that contains three variables: the `name` of the airline, e.g., `United Air Lines Inc.` not `UA`, the count (number) of times it flew to SFO, and the `percent` of the trips that that particular airline flew to SFO.

#Planes that traveled to San Francisco 

fly_into_sfo <- joint_flights_airlines %>%
  group_by(name)%>%
  summarize(total_flights = n(), number=sum(dest == "SFO", na.rm = TRUE), percent = sum(dest == "SFO", na.rm = TRUE) / total_flights *100) %>%
  filter(percent > 0) %>%
  arrange(desc(percent))%>%
  select(name, number, percent)
fly_into_sfo

```

And here is some bonus ggplot code to plot your dataframe

```{r}
# #| label: ggplot-flights-toSFO
# #| message: false
# #| warning: false
# 
# fly_into_sfo %>% 
#   
#   # sort 'name' of airline by the numbers it times to flew to SFO
#   mutate(name = fct_reorder(name, count)) %>% 
#   
#   ggplot() +
#   
#   aes(x = count, 
#       y = name) +
#   
#   # a simple bar/column plot
#   geom_col() +
#   
#   # add labels, so each bar shows the % of total flights 
#   geom_text(aes(label = percent),
#              hjust = 1, 
#              colour = "white", 
#              size = 5)+
#   
#   # add labels to help our audience  
#   labs(title="Which airline dominates the NYC to SFO route?", 
#        subtitle = "as % of total flights in 2013",
#        x= "Number of flights",
#        y= NULL) +
#   
#   theme_minimal() + 
#   
#   # change the theme-- i just googled those , but you can use the ggThemeAssist add-in
#   # https://cran.r-project.org/web/packages/ggThemeAssist/index.html
#   
#   theme(#
#     # so title is left-aligned
#     plot.title.position = "plot",
#     
#     # text in axes appears larger        
#     axis.text = element_text(size=12),
#     
#     # title text is bigger
#     plot.title = element_text(size=18)
#       ) +
# 
#   # add one final layer of NULL, so if you comment out any lines
#   # you never end up with a hanging `+` that awaits another ggplot layer
#   NULL
 
 
```

## Problem 9: Let's take a look at cancellations of flights to SFO. We create a new dataframe `cancellations` as follows

```{r}

cancellations <- flights %>% 
  
  # just filter for destination == 'SFO'
  filter(dest == 'SFO') %>% 
  
  # a cancelled flight is one with no `dep_time` 
  filter(is.na(dep_time))

cancellations
```

I want you to think how we would organize our data manipulation to create the following plot. No need to write the code, just explain in words how you would go about it.

Answer:

1.  Left join flights table with airlines table to have te full name of the airlines
2.  I would group by : name, origin, month
3.  with a column that summarizes count = n()
4.  Plot in a bar graph with x = month and y = count
5.  Finally, use facet_wrap(\~ origin) + facet_grid(origin \~ name)

![](images/sfo-cancellations.png)

## Problem 10: On your own -- Hollywood Age Gap

The website https://hollywoodagegap.com is a record of *THE AGE DIFFERENCE IN YEARS BETWEEN MOVIE LOVE INTERESTS*. This is an informational site showing the age gap between movie love interests and the data follows certain rules:

-   The two (or more) actors play actual love interests (not just friends, coworkers, or some other non-romantic type of relationship)
-   The youngest of the two actors is at least 17 years old
-   No animated characters

The age gaps dataset includes "gender" columns, which always contain the values "man" or "woman". These values appear to indicate how the characters in each film identify and some of these values do not match how the actor identifies. We apologize if any characters are misgendered in the data!

The following is a data dictionary of the variables used

| variable            | class     | description                                                                                             |
|:--------------------|:----------|:--------------------------------------------------------------------------------------------------------|
| movie_name          | character | Name of the film                                                                                        |
| release_year        | integer   | Release year                                                                                            |
| director            | character | Director of the film                                                                                    |
| age_difference      | integer   | Age difference between the characters in whole years                                                    |
| couple_number       | integer   | An identifier for the couple in case multiple couples are listed for this film                          |
| actor_1\_name       | character | The name of the older actor in this couple                                                              |
| actor_2\_name       | character | The name of the younger actor in this couple                                                            |
| character_1\_gender | character | The gender of the older character, as identified by the person who submitted the data for this couple   |
| character_2\_gender | character | The gender of the younger character, as identified by the person who submitted the data for this couple |
| actor_1\_birthdate  | date      | The birthdate of the older member of the couple                                                         |
| actor_2\_birthdate  | date      | The birthdate of the younger member of the couple                                                       |
| actor_1\_age        | integer   | The age of the older actor when the film was released                                                   |
| actor_2\_age        | integer   | The age of the younger actor when the film was released                                                 |

```{r}

age_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')

#  How is `age_difference` distributed? What's the 'typical' `age_difference` in movies?

ggplot(age_gaps, aes(x=age_difference)) + 
  geom_histogram(binwidth = 1)

#How frequently does this rule apply in this dataset?

half_plus_seven <- age_gaps %>%
  mutate(lower_bound = actor_1_age/2+7, upper_bound = (actor_1_age-7)*2) %>%
  mutate(rule_ok = ifelse(actor_2_age >= lower_bound & actor_2_age <= upper_bound, "Yes", "No")) 

frequency_rule_yes <- half_plus_seven %>%
  summarise(total_movies = n(), percent_rule_yes = sum(rule_ok == "Yes", na.rm = TRUE)/total_movies*100) %>%
  select(percent_rule_yes)

frequency_rule_yes

#Which movie has the greatest number of love interests?

love_interests_movies <- age_gaps %>%
  group_by(movie_name)%>% 
  summarize(couple_number = n())%>%
  arrange(desc(couple_number))

love_interests_movies


#Which actors/ actresses have the greatest number of love interests in this dataset?
  
love_interests_actors1 <- age_gaps %>% 
  group_by(actor_name = actor_1_name)%>% 
  summarize(couple_number = n())%>%
  arrange(desc(couple_number))

love_interests_actors2 <- age_gaps %>% 
  group_by(actor_name = actor_2_name)%>% 
  summarize(couple_number = n())%>%
  arrange(desc(couple_number))  

love_interests_actors<- rbind(love_interests_actors1, love_interests_actors2) %>%
  arrange(desc(couple_number))

love_interests_actors

#Is the mean/median age difference staying constant over the years (1935 - 2022)?


mm_age_diff <- age_gaps %>%
  group_by(release_year) %>%
  summarise(mean=mean(age_difference), median = median(age_difference)) %>%
  pivot_longer(
    cols = 2:3,
    names_to = "parameter",
    values_to = "value"
  )

mm_age_diff


ggplot(mm_age_diff, aes(x=release_year, y = value, color = parameter)) + geom_point() + geom_smooth(aes(y = value), level = 0)

ggplot(mm_age_diff, aes(x=release_year, y = value, color = parameter)) + geom_line() 

#How frequently does Hollywood depict same-gender love interests?

same_gender <- age_gaps %>%
  mutate(gender_equal = ifelse(character_1_gender == character_2_gender, "Yes", "No"))%>%
  summarise(total_movies = n(), percent_same_gender = sum(gender_equal == "Yes", na.rm = TRUE)/total_movies*100) %>%
  select(percent_same_gender)

same_gender

```

How would you explore this data set? Here are some ideas of tables/ graphs to help you with your analysis

-   How is `age_difference` distributed? What's the 'typical' `age_difference` in movies?

-   The `half plus seven\` rule. Large age disparities in relationships carry certain stigmas. One popular rule of thumb is the [half-your-age-plus-seven](https://en.wikipedia.org/wiki/Age_disparity_in_sexual_relationships#The_.22half-your-age-plus-seven.22_rule) rule. This rule states you should never date anyone under half your age plus seven, establishing a minimum boundary on whom one can date. In order for a dating relationship to be acceptable under this rule, your partner's age must be:

$$\frac{\text{Your age}}{2} + 7 < \text{Partner Age} < (\text{Your age} - 7) * 2$$ How frequently does this rule apply in this dataset?

-   Which movie has the greatest number of love interests?
-   Which actors/ actresses have the greatest number of love interests in this dataset?
-   Is the mean/median age difference staying constant over the years (1935 - 2022)?
-   How frequently does Hollywood depict same-gender love interests?

# Deliverables

There is a lot of explanatory text, comments, etc. You do not need these, so delete them and produce a stand-alone document that you could share with someone. Render the edited and completed Quarto Markdown (qmd) file as a Word document (use the "Render" button at the top of the script editor window) and upload it to Canvas. You must be committing and pushing tour changes to your own Github repo as you go along.

# Details

-   Who did you collaborate with: Nicholas Arnovitz, Angela Zhong, Harry Heo, Deven Jonbanputra
-   Approximately how much time did you spend on this problem set: 10 Hours
-   What, if anything, gave you the most trouble: group_by

**Please seek out help when you need it,** and remember the [15-minute rule](https://mam2022.netlify.app/syllabus/#the-15-minute-rule){target="_blank"}. You know enough R (and have enough examples of code from class and your readings) to be able to do this. If you get stuck, ask for help from others, post a question on Slack-- and remember that I am here to help too!

> As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else?

# Rubric

13/13: Problem set is 100% completed. Every question was attempted and answered, and most answers are correct. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output. Multiple Github commits. Work is exceptional. I will not assign these often.

8/13: Problem set is 60--80% complete and most answers are correct. This is the expected level of performance. Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). A few Github commits.

5/13: Problem set is less than 60% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not assign these often. Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. No Github commits.
